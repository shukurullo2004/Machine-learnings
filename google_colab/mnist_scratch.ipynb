{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMT7z+ni6mLn7qe3f8KggGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shukurullo2004/Machine-learnings/blob/main/mnist_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "torch.manual_seed(42)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "rpALu6Bj4S7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate([x.numpy().reshape(-1, 28*28) for x, _ in train_loader])\n",
        "y_train = np.concatenate([y.numpy() for _, y in train_loader])\n",
        "\n",
        "X_test = np.concatenate([x.numpy().reshape(-1, 28*28) for x, _ in test_loader])\n",
        "y_test = np.concatenate([y.numpy() for _, y in test_loader])\n"
      ],
      "metadata": {
        "id": "m-C9Qex5OyT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "parameters = {}\n",
        "def init_params():\n",
        "    global parameters\n",
        "\n",
        "    input_size = 28 * 28\n",
        "    hidden_size = 128\n",
        "    output_size = 10\n",
        "\n",
        "    parameters['W1'] = np.random.randn(input_size, hidden_size)\n",
        "    parameters['b1'] = np.zeros((1, hidden_size))\n",
        "    parameters['W2'] = np.random.randn(hidden_size, hidden_size)\n",
        "    parameters['b2'] = np.zeros((1, hidden_size))\n",
        "    parameters['W3'] = np.random.randn(hidden_size, output_size)\n",
        "    parameters['b3'] = np.zeros((1, output_size))\n",
        "\n",
        "    return parameters\n",
        "init_params()\n",
        "parameters.keys()"
      ],
      "metadata": {
        "id": "85EThHiuDNGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "def linear(x,w,b):\n",
        "  return (np.dot(x,w)+b)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_values = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "    return probabilities\n"
      ],
      "metadata": {
        "id": "3h-PZM5_DNJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    W1, b1, W2, b2, W3, b3 = (\n",
        "        parameters['W1'],\n",
        "        parameters['b1'],\n",
        "        parameters['W2'],\n",
        "        parameters['b2'],\n",
        "        parameters['W3'],\n",
        "        parameters['b3']\n",
        "    )\n",
        "\n",
        "    z1 = linear(X,W1,b1)\n",
        "    a1 = relu(z1)\n",
        "\n",
        "    z2 = linear(a1,W2,b2)\n",
        "    a2 = relu(z2)\n",
        "\n",
        "    z3 = linear(a2,W3,b3)\n",
        "    y_pred = softmax(z3)\n",
        "    return y_pred, {'a1':a1, 'a2':a2, 'y_pred':y_pred}\n",
        "\n",
        "def backward_propagation(X, y_true, parameters, cache):\n",
        "    m = X.shape[0]\n",
        "    W1, b1, W2, b2, W3, b3 = (\n",
        "        parameters['W1'], parameters['b1'],\n",
        "        parameters['W2'], parameters['b2'],\n",
        "        parameters['W3'], parameters['b3']\n",
        "    )\n",
        "    a1, a2, y_pred = cache['a1'], cache['a2'], cache['y_pred']\n",
        "\n",
        "    dz3 = y_pred - y_true\n",
        "    dW3 = np.dot(a2.T, dz3) / m\n",
        "    db3 = np.sum(dz3, axis=0, keepdims=True) / m\n",
        "\n",
        "    dz2 = np.dot(dz3, W3.T) * (a2 > 0)\n",
        "    dW2 = np.dot(a1.T, dz2) / m\n",
        "    db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
        "\n",
        "    dz1 = np.dot(dz2, W2.T) * (a1 > 0)\n",
        "    dW1 = np.dot(X.T, dz1) / m\n",
        "    db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
        "\n",
        "    gradients = {'W1': dW1, 'b1': db1, 'W2': dW2, 'b2': db2, 'W3': dW3, 'b3': db3}\n",
        "\n",
        "    return gradients\n",
        "\n",
        "def sparse_categorical_crossentropy(probabilities, targets, epsilon=1e-10):\n",
        "    num_samples = probabilities.shape[0]\n",
        "\n",
        "    # Add epsilon to avoid log(0)\n",
        "    probabilities = np.clip(probabilities, epsilon, 1 - epsilon)\n",
        "\n",
        "    predicted_probabilities = probabilities[np.arange(num_samples), targets]\n",
        "\n",
        "    negative_log_probabilities = -np.log(predicted_probabilities)\n",
        "\n",
        "    loss = np.sum(negative_log_probabilities) / num_samples\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def update_parameters(parameters, gradients, learning_rate):\n",
        "    for param_name in parameters.keys():\n",
        "        parameters[param_name] -= learning_rate * gradients[param_name]"
      ],
      "metadata": {
        "id": "tMLyUFOhqZ_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "    y_pred_indices = np.argmax(y_pred, axis=1)\n",
        "    correct = np.sum(y_true == y_pred_indices)\n",
        "    acc = (correct / len(y_true)) * 100\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "AB1WP9FPZG2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(labels, num_classes):\n",
        "    encoded_labels = np.zeros((len(labels), num_classes))\n",
        "    for i, label in enumerate(labels):\n",
        "        encoded_labels[i, label] = 1\n",
        "    return encoded_labels\n",
        "\n",
        "y_train_one_hot = one_hot_encode(y_train, num_classes=10)"
      ],
      "metadata": {
        "id": "qGmjcUplSSWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_params()\n",
        "epochs =300\n",
        "\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    y_pred, cache = forward_propagation(X_train, parameters)\n",
        "\n",
        "    # One-hot encode labels\n",
        "    y_train_one_hot = one_hot_encode(y_train, 10)\n",
        "\n",
        "    loss = sparse_categorical_crossentropy(y_pred, y_train)\n",
        "    acc = accuracy_fn(y_train, y_pred)\n",
        "    gradients = backward_propagation(X_train, y_train_one_hot, parameters, cache)\n",
        "\n",
        "    update_parameters(parameters, gradients, learning_rate=0.01)\n",
        "    train_loss.append(loss)\n",
        "    train_acc.append(acc)\n",
        "    if epoch % 10 == 0:\n",
        "\n",
        "        print(f'Epoch {epoch}, Loss: {loss}, Acc: {acc}')"
      ],
      "metadata": {
        "id": "smimHf7yk2V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "epoch_range = range(epochs)\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch_range, train_loss, label='Training Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch_range, train_acc, label='Training Accuracy', color='orange')\n",
        "# plt.title('Training Accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy (%)')\n",
        "# plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WRo7oavAlFpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def plot_images(images, true_labels, pred_labels):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for i in range(len(images)):\n",
        "        plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
        "        plt.title(f'True: {true_labels[i]}\\nPred: {pred_labels[i]}')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "num_samples_to_plot = 10\n",
        "random_indices = random.sample(range(len(X_test)), num_samples_to_plot)\n",
        "sample_images = X_test[random_indices]\n",
        "true_labels = y_test[random_indices]\n",
        "\n",
        "y_pred, _ = forward_propagation(sample_images, parameters)\n",
        "pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "plot_images(sample_images, true_labels, pred_labels)\n"
      ],
      "metadata": {
        "id": "TaJSHapFlFsG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}